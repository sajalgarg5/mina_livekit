<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <title>Recall.ai Real-time Audio Agent</title>
    <style>
        body { display: flex; flex-direction: column; justify-content: center; align-items: center; height: 100vh; margin: 0; background: #0c0cf8; font-family: sans-serif; color: white; }
        .status-indicator { width: 150px; height: 150px; border-radius: 50%; background-color: #82baf7; display: flex; justify-content: center; align-items: center; margin-bottom: 20px; transition: 0.3s; }
        .speaking { background-color: #00d2ff; box-shadow: 0 0 50px #00d2ff; transform: scale(1.1); }
        .icon { font-size: 60px; }
        #statusText { font-size: 18px; font-weight: bold; text-transform: uppercase; }
        #log { margin-top: 20px; font-size: 12px; width: 80%; height: 120px; overflow-y: auto; background: rgba(0,0,0,0.2); padding: 10px; border-radius: 6px; }
    </style>
</head>
<body>
    <div class="status-indicator" id="statusIndicator"><div class="icon">‚óè</div></div>
    <div id="statusText">Connecting‚Ä¶</div>
    <div id="log"></div>

<script>
const BASE_URL = "https://cabinet-event-tricks-alarm.trycloudflare.com";
const SAMPLE_RATE = 16000;
const MIN_BUFFER_SIZE = 128; 

let audioContextPlayback = null;
let audioBuffer = new Uint8Array(0);
let isPlayingAudio = false;
window.audioInterrupted = false;

function log(msg) {
    const el = document.getElementById("log");
    el.innerHTML += `[${new Date().toLocaleTimeString()}] ${msg}<br>`;
    el.scrollTop = el.scrollHeight;
}

function queueAudioChunk(base64Audio) {
    try {
        const binaryString = atob(base64Audio);
        const chunk = new Uint8Array(binaryString.length);
        for (let i = 0; i < binaryString.length; i++) {
            chunk[i] = binaryString.charCodeAt(i);
        }

        // Append to master buffer
        const newBuffer = new Uint8Array(audioBuffer.length + chunk.length);
        newBuffer.set(audioBuffer);
        newBuffer.set(chunk, audioBuffer.length);
        audioBuffer = newBuffer;

        // Reference Logic: Play when buffer is large enough
        if (audioBuffer.length >= MIN_BUFFER_SIZE && !isPlayingAudio && !window.audioInterrupted) {
            playBufferedAudio();
        }
    } catch (error) {
        console.error("Error queueing audio chunk:", error);
    }
}

async function playBufferedAudio() {
    if (window.audioInterrupted) {
        isPlayingAudio = false;
        return;
    }

    if (audioBuffer.length === 0) {
        isPlayingAudio = false;
        return;
    }

    isPlayingAudio = true;
    document.getElementById("statusIndicator").classList.add("speaking");

    try {
        if (!audioContextPlayback) {
            audioContextPlayback = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: SAMPLE_RATE });
        }
        if (audioContextPlayback.state === "suspended") {
            await audioContextPlayback.resume();
        }

        // --- FIXED BUFFER SLICING ---
        // Instead of taking EVERYTHING, we take exactly MIN_BUFFER_SIZE
        // This leaves the rest of the incoming data for the NEXT onended call
        const chunkSize = Math.max(MIN_BUFFER_SIZE, audioBuffer.length);
        const chunkToPlay = audioBuffer.slice(0, chunkSize);
        audioBuffer = audioBuffer.slice(chunkSize);

        const sampleCount = chunkToPlay.length / 2;
        const audioBufferNode = audioContextPlayback.createBuffer(1, sampleCount, SAMPLE_RATE);
        const channelData = audioBufferNode.getChannelData(0);
        const dataView = new DataView(chunkToPlay.buffer);

        for (let i = 0; i < sampleCount; i++) {
            const sample = dataView.getInt16(i * 2, true);
            channelData[i] = sample / 32768.0;
        }

        const source = audioContextPlayback.createBufferSource();
        window.currentAudioSource = source; 
        source.buffer = audioBufferNode;
        source.connect(audioContextPlayback.destination);

        // Reference Logic: use onended to trigger the next chunk
        source.onended = () => {
            if (window.audioInterrupted) {
                isPlayingAudio = false;
                document.getElementById("statusIndicator").classList.remove("speaking");
                return;
            }

            if (audioBuffer.length >= MIN_BUFFER_SIZE) {
                playBufferedAudio();
            } else {
                isPlayingAudio = false;
                document.getElementById("statusIndicator").classList.remove("speaking");
                
                // Reference Logic: Check again after 10ms
                window.audioPlaybackTimeout = setTimeout(() => {
                    if (!window.audioInterrupted && audioBuffer.length >= MIN_BUFFER_SIZE) {
                        playBufferedAudio();
                    }
                }, 10);
            }
        };

        const currentTime = audioContextPlayback.currentTime;
        source.start(currentTime);

    } catch (error) {
        console.error("Error playing audio:", error);
        isPlayingAudio = false;
    }
}

function connectSSE() {
    log("üîå Connecting...");
    document.getElementById("statusText").textContent = "Connecting‚Ä¶";
    const eventSource = new EventSource(`${BASE_URL}/listen_audio`);

    eventSource.onopen = () => {
        log("‚úÖ Connected");
        document.getElementById("statusText").textContent = "Live Streaming";
    };

    eventSource.addEventListener("audio", (event) => {
        queueAudioChunk(event.data);
    });

    eventSource.onerror = () => {
        eventSource.close();
        setTimeout(connectSSE, 3000);
    };
}

window.addEventListener("click", () => {
    if (audioContextPlayback && audioContextPlayback.state === "suspended") {
        audioContextPlayback.resume();
    }
});

window.onload = connectSSE;
</script>
</body>
</html>