<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <title>Recall.ai Real-time Audio Agent</title>
    <style>
        body { display: flex; flex-direction: column; justify-content: center; align-items: center; height: 100vh; margin: 0; background: #0c0cf8; font-family: sans-serif; color: white; }
        .status-indicator { width: 150px; height: 150px; border-radius: 50%; background-color: #82baf7; display: flex; justify-content: center; align-items: center; margin-bottom: 20px; transition: 0.3s; }
        .speaking { background-color: #00d2ff; box-shadow: 0 0 50px #00d2ff; transform: scale(1.1); }
        .icon { font-size: 60px; }
        #statusText { font-size: 18px; font-weight: bold; text-transform: uppercase; }
        #log { margin-top: 20px; font-size: 12px; width: 80%; height: 120px; overflow-y: auto; background: rgba(0,0,0,0.2); padding: 10px; border-radius: 6px; font-family: monospace; }
    </style>
</head>
<body>
    <div class="status-indicator" id="statusIndicator"><div class="icon">‚óè</div></div>
    <div id="statusText">Connecting‚Ä¶</div>
    <div id="log"></div>

<script>
/* ------------------------------------------------------------------
   CONFIG & GLOBAL STATE
------------------------------------------------------------------- */
const BASE_URL = "https://tel-retreat-pure-education.trycloudflare.com";
const SAMPLE_RATE = 16000;
const MIN_BUFFER_SIZE = 3200; // Increased slightly for better safety (200ms)

let audioContextPlayback = null;
let audioBuffer = new Uint8Array(0);
let isPlayingAudio = false;
let nextStartTime = 0; // The global "clock" that stitches audio chunks
window.audioInterrupted = false;

function log(msg) {
    const el = document.getElementById("log");
    el.innerHTML += `[${new Date().toLocaleTimeString()}] ${msg}<br>`;
    el.scrollTop = el.scrollHeight;
}

/* ------------------------------------------------------------------
   BUFFER HANDLING
------------------------------------------------------------------- */
function queueAudioChunk(base64Audio) {
    try {
        const binaryString = atob(base64Audio);
        const chunk = new Uint8Array(binaryString.length);
        for (let i = 0; i < binaryString.length; i++) {
            chunk[i] = binaryString.charCodeAt(i);
        }

        // Append to master buffer
        const newBuffer = new Uint8Array(audioBuffer.length + chunk.length);
        newBuffer.set(audioBuffer);
        newBuffer.set(chunk, audioBuffer.length);
        audioBuffer = newBuffer;

        // Start playback if we have enough data and aren't already playing
        if (audioBuffer.length >= MIN_BUFFER_SIZE && !isPlayingAudio && !window.audioInterrupted) {
            playBufferedAudio();
        }
    } catch (error) {
        console.error("Error queueing audio chunk:", error);
    }
}

/* ------------------------------------------------------------------
   PLAYBACK ENGINE (STITCHING LOGIC)
------------------------------------------------------------------- */
async function playBufferedAudio() {
    if (window.audioInterrupted || audioBuffer.length === 0) {
        isPlayingAudio = false;
        document.getElementById("statusIndicator").classList.remove("speaking");
        return;
    }

    isPlayingAudio = true;
    document.getElementById("statusIndicator").classList.add("speaking");

    try {
        if (!audioContextPlayback) {
            audioContextPlayback = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: SAMPLE_RATE });
        }
        if (audioContextPlayback.state === "suspended") {
            await audioContextPlayback.resume();
        }

        // Take a chunk from the buffer (Step-by-step processing)
        const chunkSize = Math.min(MIN_BUFFER_SIZE, audioBuffer.length);
        const chunkToPlay = audioBuffer.slice(0, chunkSize);
        audioBuffer = audioBuffer.slice(chunkSize);

        const sampleCount = chunkToPlay.length / 2;
        const audioBufferNode = audioContextPlayback.createBuffer(1, sampleCount, SAMPLE_RATE);
        const channelData = audioBufferNode.getChannelData(0);
        const dataView = new DataView(chunkToPlay.buffer);

        // Convert PCM16 to Float32
        for (let i = 0; i < sampleCount; i++) {
            channelData[i] = dataView.getInt16(i * 2, true) / 32768.0;
        }

        const source = audioContextPlayback.createBufferSource();
        source.buffer = audioBufferNode;
        source.connect(audioContextPlayback.destination);

        // --- THE STITCHING MATH ---
        const currentTime = audioContextPlayback.currentTime;

        // If the clock is in the past (first run or lag), reset it to 'now' + small cushion
        if (nextStartTime < currentTime) {
            nextStartTime = currentTime + 0.1; 
        }

        // Schedule the start at the exact end of the previous chunk
        source.start(nextStartTime);

        // Update the global clock by adding this chunk's duration
        nextStartTime += audioBufferNode.duration;

        // Use a lookahead Timeout to queue the next piece BEFORE this one ends
        // This is much faster and more reliable than the 'onended' event
        const lookaheadMs = (audioBufferNode.duration * 1000) - 25; 
        
        setTimeout(() => {
            if (!window.audioInterrupted && audioBuffer.length > 0) {
                playBufferedAudio();
            } else {
                // If no more data, we'll wait for the last source to finish visually
                source.onended = () => {
                   if (audioContextPlayback.currentTime >= nextStartTime - 0.05) {
                       document.getElementById("statusIndicator").classList.remove("speaking");
                       isPlayingAudio = false;
                   }
                };
            }
        }, Math.max(0, lookaheadMs));

    } catch (error) {
        console.error("Error playing audio:", error);
        isPlayingAudio = false;
    }
}

/* ------------------------------------------------------------------
   NETWORK & INITIALIZATION
------------------------------------------------------------------- */
function connectSSE() {
    log("üîå Connecting to Audio Stream...");
    document.getElementById("statusText").textContent = "Connecting‚Ä¶";
    
    const eventSource = new EventSource(`${BASE_URL}/listen_audio`);

    eventSource.onopen = () => {
        log("‚úÖ Connected to Backend");
        document.getElementById("statusText").textContent = "Live Streaming";
    };

    eventSource.addEventListener("audio", (event) => {
        queueAudioChunk(event.data);
    });

    eventSource.onerror = () => {
        log("‚ö†Ô∏è Connection lost. Retrying...");
        eventSource.close();
        setTimeout(connectSSE, 3000);
    };
}

// User interaction required to "unlock" audio in modern browsers
window.addEventListener("click", () => {
    if (audioContextPlayback && audioContextPlayback.state === "suspended") {
        audioContextPlayback.resume();
        log("üîä Audio Context Resumed via click");
    }
});

window.onload = connectSSE;
</script>
</body>
</html>