<!DOCTYPE html>
<html>
<head>
    <title>Recall.ai Real-time Audio Agent</title>
    <style>
        body { display: flex; flex-direction: column; justify-content: center; align-items: center; height: 100vh; margin: 0; background: linear-gradient(135deg, #0c0cf8 0%, #0b0beb 100%); font-family: 'Segoe UI', sans-serif; }
        .status-indicator { width: 150px; height: 150px; border-radius: 50%; background-color: #82baf7; display: flex; justify-content: center; align-items: center; margin-bottom: 20px; transition: all 0.5s ease; box-shadow: 0 0 20px rgba(0,0,0,0.5); }
        .status-indicator.speaking { background-color: #00d2ff; box-shadow: 0 0 50px rgba(0, 210, 255, 0.6); animation: pulse 1.5s infinite ease-in-out; }
        @keyframes pulse { 0% { transform: scale(1); } 50% { transform: scale(1.1); } 100% { transform: scale(1); } }
        .icon { font-size: 60px; color: white; }
        .status-text { color: white; font-size: 24px; font-weight: 300; }
    </style>
</head>
<body>

    <div class="status-indicator idle" id="statusIndicator"><div class="icon">‚óè</div></div>
    <div class="status-text" id="statusText">CLICK TO START LISTENING</div>

    <script>
        const statusIndicator = document.getElementById('statusIndicator');
        const statusText = document.getElementById('statusText');

        const WS_URL = "wss://driven-emily-causing-powers.trycloudflare.com/ws/rt";
        
        let audioCtx;
        let nextStartTime = 0;

        // Recall.ai default PCM settings: 16kHz, Mono, 16-bit
        const SAMPLE_RATE = 16000; 

        function init() {
            audioCtx = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: SAMPLE_RATE });
            const socket = new WebSocket(WS_URL);

            socket.onopen = () => {
                statusText.textContent = "CONNECTED TO RECALL.AI";
            };

            socket.onmessage = async (event) => {
                try {
                    const msg = JSON.parse(event.data);
                    
                    // Check if this is the correct audio data event
                    if (msg.event === "audio_mixed_raw.data") {
                        const base64Buffer = msg.data.data.buffer;
                        playRawPCM(base64Buffer);
                    }
                } catch (e) {
                    console.error("Error parsing JSON or Audio:", e);
                }
            };

            socket.onclose = () => {
                statusText.textContent = "DISCONNECTED";
            };
        }

        function playRawPCM(base64) {
            // 1. Decode Base64 to binary
            const binaryString = window.atob(base64);
            const len = binaryString.length;
            const bytes = new Int16Array(len / 2); // 16-bit audio uses 2 bytes per sample

            // 2. Convert to 16-bit Integers
            const dataView = new DataView(new Uint8Array(Array.from(binaryString, c => c.charCodeAt(0))).buffer);
            for (let i = 0; i < bytes.length; i++) {
                bytes[i] = dataView.getInt16(i * 2, true); // true for little-endian
            }

            // 3. Convert Int16 to Float32 (required by Web Audio API)
            const float32Data = new Float32Array(bytes.length);
            for (let i = 0; i < bytes.length; i++) {
                float32Data[i] = bytes[i] / 32768; // Normalize to [-1.0, 1.0]
            }

            // 4. Create and play the buffer
            const audioBuffer = audioCtx.createBuffer(1, float32Data.length, SAMPLE_RATE);
            audioBuffer.getChannelData(0).set(float32Data);

            const source = audioCtx.createBufferSource();
            source.buffer = audioBuffer;
            source.connect(audioCtx.destination);

            // Scheduling logic to prevent gaps
            const currentTime = audioCtx.currentTime;
            if (nextStartTime < currentTime) {
                nextStartTime = currentTime;
            }

            source.start(nextStartTime);
            nextStartTime += audioBuffer.duration;

            // Visual State
            setVisualState('speaking');
            source.onended = () => {
                if (audioCtx.currentTime >= nextStartTime - 0.1) {
                    setVisualState('idle');
                }
            };
        }

        function setVisualState(state) {
            if (state === 'speaking') {
                statusIndicator.className = 'status-indicator speaking';
                statusIndicator.innerHTML = '<div class="icon">üé§</div>';
            } else {
                statusIndicator.className = 'status-indicator idle';
                statusIndicator.innerHTML = '<div class="icon">‚óè</div>';
            }
        }

        window.onload = () => { init(); };
    </script>
</body>
</html>