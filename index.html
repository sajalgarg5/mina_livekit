<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <title>Recall Bot - Zero Lag Stream</title>
    <style>
        body { display: flex; flex-direction: column; justify-content: center; align-items: center; height: 100vh; margin: 0; background: #000022; color: white; font-family: sans-serif; overflow: hidden; }
        .status-indicator { width: 100px; height: 100px; border-radius: 50%; background-color: #222; border: 4px solid #444; }
        .speaking { background-color: #00d2ff; box-shadow: 0 0 30px #00d2ff; }
        #log { margin-top: 20px; font-size: 10px; width: 90%; height: 80px; overflow-y: auto; background: rgba(0,0,0,0.4); padding: 10px; font-family: monospace; }
    </style>
</head>
<body>
    <div class="status-indicator" id="statusIndicator"></div>
    <div id="statusText" style="margin-top:10px;">CPU Offloading Enabled...</div>
    <div id="log"></div>

<script type="module">
    import { AudioAnalysis } from './audio_analysis.js';

    const BASE_URL = "https://tel-retreat-pure-education.trycloudflare.com"; 
    const SAMPLE_RATE = 16000;

    let audioCtx, streamNode, analyser, decoderWorker;
    let leftoverByte = null;

    function log(msg) {
        const el = document.getElementById("log");
        el.innerHTML += `<div>[${new Date().toLocaleTimeString()}] ${msg}</div>`;
        el.scrollTop = el.scrollHeight;
    }

    async function initAudio() {
        if (audioCtx) return;
        try {
            audioCtx = new (window.AudioContext || window.webkitAudioContext)({ 
                sampleRate: SAMPLE_RATE,
                latencyHint: 'playback' 
            });

            // 1. Setup the Web Worker for background decoding
            decoderWorker = new Worker('decoder_worker.js');
            
            // 2. Setup the Audio Engine
            await audioCtx.audioWorklet.addModule('stream_processor.js');
            streamNode = new AudioWorkletNode(audioCtx, 'stream_processor');
            analyser = audioCtx.createAnalyser();
            analyser.fftSize = 256; // Extreme low CPU mode
            
            streamNode.connect(analyser);
            analyser.connect(audioCtx.destination);
            await audioCtx.resume();

            // 3. Handle data coming BACK from the worker
            decoderWorker.onmessage = (e) => {
                let bytes = new Uint8Array(e.data);
                
                // Stitch PCM alignment
                if (leftoverByte !== null) {
                    let stitched = new Uint8Array(bytes.length + 1);
                    stitched[0] = leftoverByte; stitched.set(bytes, 1);
                    bytes = stitched; leftoverByte = null;
                }
                if (bytes.length % 2 !== 0) {
                    leftoverByte = bytes[bytes.length - 1];
                    bytes = bytes.slice(0, -1);
                }

                // Rapid Float32 conversion
                const float32 = new Float32Array(bytes.length / 2);
                const view = new DataView(bytes.buffer);
                for (let i = 0; i < float32.length; i++) {
                    float32[i] = view.getInt16(i * 2, true) / 32768;
                }
                streamNode.port.postMessage({ event: 'write', buffer: float32 });
            };

            log("âœ… Audio Engine & Worker Ready");
            connectSSE();
            startVisualizer();
        } catch (e) {
            log("âŒ Error: " + e.message);
        }
    }

    function connectSSE() {
        const ev = new EventSource(`${BASE_URL}/listen_audio`);
        
        ev.addEventListener("audio", (e) => {
            // Simply pass the string to the worker. 
            // The Main Thread does ZERO work here.
            if(decoderWorker) decoderWorker.postMessage(e.data);
        });

        ev.onopen = () => log("ðŸ”Œ SSE Connected");
        ev.onerror = () => {
            ev.close();
            setTimeout(connectSSE, 2000);
        };
    }

    function startVisualizer() {
        const indicator = document.getElementById("statusIndicator");
        const update = () => {
            requestAnimationFrame(update);
            if (!analyser) return;
            const data = AudioAnalysis.getFrequencies(analyser, SAMPLE_RATE, null, 'voice');
            const vol = data.values.reduce((a, b) => a + b, 0) / data.values.length;
            indicator.className = (vol > 0.04) ? "status-indicator speaking" : "status-indicator";
        };
        update();
    }

    window.onload = () => setTimeout(initAudio, 3000);
</script>
</body>
</html>