<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<title>Recall.ai Real-time Audio Agent</title>

<style>
body {
    display: flex;
    flex-direction: column;
    justify-content: center;
    align-items: center;
    height: 100vh;
    margin: 0;
    background: #0c0cf8;
    font-family: sans-serif;
    color: white;
}

.status-indicator {
    width: 150px;
    height: 150px;
    border-radius: 50%;
    background-color: #82baf7;
    display: flex;
    justify-content: center;
    align-items: center;
    margin-bottom: 20px;
    transition: 0.3s;
}

.speaking {
    background-color: #00d2ff;
    box-shadow: 0 0 50px #00d2ff;
    transform: scale(1.1);
}

.icon {
    font-size: 60px;
}

#statusText {
    font-size: 18px;
    font-weight: bold;
    text-transform: uppercase;
}

#log {
    margin-top: 20px;
    font-size: 12px;
    width: 80%;
    height: 150px;
    overflow-y: auto;
    background: rgba(0,0,0,0.25);
    padding: 10px;
    border-radius: 6px;
}
</style>
</head>

<body>

<div class="status-indicator" id="statusIndicator">
    <div class="icon">‚óè</div>
</div>

<div id="statusText">Connecting‚Ä¶</div>
<div id="log"></div>

<script>
/* ================= CONFIG ================= */

const BASE_URL = "https://tel-retreat-pure-education.trycloudflare.com";
const SAMPLE_RATE = 16000;
const MIN_BUFFER_SIZE = 2048;          // ~64ms @16kHz
const STARTUP_DELAY_MS = 200;          // warm-up delay
const RECONNECT_DELAY_MS = 3000;

/* ================= STATE ================= */

let audioContext = null;
let audioBuffer = new Uint8Array(0);
let isPlaying = false;
let playbackAllowed = false;
let startupTimer = null;
let eventSource = null;

/* ================= UTIL ================= */

function log(msg) {
    const el = document.getElementById("log");
    el.innerHTML += `[${new Date().toLocaleTimeString()}] ${msg}<br>`;
    el.scrollTop = el.scrollHeight;
}

/* ================= AUDIO ================= */

async function ensureAudioContext() {
    if (!audioContext) {
        audioContext = new (window.AudioContext || window.webkitAudioContext)({
            sampleRate: SAMPLE_RATE
        });
        log("üéß AudioContext created");
    }
    if (audioContext.state === "suspended") {
        await audioContext.resume();
        log("‚ñ∂Ô∏è AudioContext resumed");
    }
}

async function queueAudioChunk(base64Audio) {
    try {
        const binary = atob(base64Audio);
        const chunk = new Uint8Array(binary.length);
        for (let i = 0; i < binary.length; i++) {
            chunk[i] = binary.charCodeAt(i);
        }

        const merged = new Uint8Array(audioBuffer.length + chunk.length);
        merged.set(audioBuffer);
        merged.set(chunk, audioBuffer.length);
        audioBuffer = merged;

        if (
            playbackAllowed &&
            audioBuffer.length >= MIN_BUFFER_SIZE &&
            !isPlaying
        ) {
            await playBufferedAudio();
        }

    } catch (err) {
        console.error("queueAudioChunk error:", err);
    }
}

async function playBufferedAudio() {
    if (isPlaying || audioBuffer.length < MIN_BUFFER_SIZE) return;

    isPlaying = true;
    document.getElementById("statusIndicator").classList.add("speaking");

    try {
        await ensureAudioContext();

        const chunkSize = Math.min(MIN_BUFFER_SIZE, audioBuffer.length);
        const chunk = audioBuffer.slice(0, chunkSize);
        audioBuffer = audioBuffer.slice(chunkSize);

        const samples = chunk.length / 2;
        const buffer = audioContext.createBuffer(1, samples, SAMPLE_RATE);
        const channel = buffer.getChannelData(0);
        const view = new DataView(chunk.buffer);

        for (let i = 0; i < samples; i++) {
            channel[i] = view.getInt16(i * 2, true) / 32768;
        }

        const source = audioContext.createBufferSource();
        source.buffer = buffer;
        source.connect(audioContext.destination);

        source.onended = async () => {
            isPlaying = false;
            document.getElementById("statusIndicator").classList.remove("speaking");

            if (audioBuffer.length >= MIN_BUFFER_SIZE && playbackAllowed) {
                await playBufferedAudio();
            }
        };

        source.start(audioContext.currentTime);

    } catch (err) {
        console.error("playBufferedAudio error:", err);
        isPlaying = false;
    }
}

/* ================= SSE ================= */

async function connectSSE() {
    log("üîå Connecting SSE‚Ä¶");
    document.getElementById("statusText").textContent = "Connecting‚Ä¶";

    playbackAllowed = false;
    if (startupTimer) clearTimeout(startupTimer);

    if (eventSource) {
        eventSource.close();
    }

    eventSource = new EventSource(`${BASE_URL}/listen_audio`);

    eventSource.onopen = async () => {
        log("‚úÖ SSE Connected");
        document.getElementById("statusText").textContent = "Live Streaming";

        await ensureAudioContext();

        startupTimer = setTimeout(() => {
            playbackAllowed = true;
            log("üéö Playback enabled after warm-up");
        }, STARTUP_DELAY_MS);
    };

    eventSource.addEventListener("audio", async (event) => {
        await queueAudioChunk(event.data);
    });

    eventSource.onerror = () => {
        log("‚ùå SSE error ‚Äî reconnecting");
        document.getElementById("statusText").textContent = "Reconnecting‚Ä¶";
        playbackAllowed = false;
        eventSource.close();
        setTimeout(connectSSE, RECONNECT_DELAY_MS);
    };
}

/* ================= USER GESTURE ================= */

window.addEventListener("click", async () => {
    await ensureAudioContext();
});

/* ================= START ================= */

window.onload = async () => {
    log("üöÄ Page loaded");
    await connectSSE();

    setTimeout(() => {
        playbackAllowed = true;
        log("üéö Playback enabled after delay");
    }, 300);
};
</script>

</body>
</html>
