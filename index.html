<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <title>Recall Bot Audio - Async Stable Stream</title>
    <style>
        body { 
            display: flex; flex-direction: column; justify-content: center; align-items: center; 
            height: 100vh; margin: 0; background: #000033; font-family: sans-serif; color: white; 
            overflow: hidden;
        }
        .status-indicator { 
            width: 100px; height: 100px; border-radius: 50%; background-color: #333; 
            border: 4px solid rgba(255,255,255,0.1); transition: background-color 0.2s; 
        }
        .speaking { background-color: #00d2ff; box-shadow: 0 0 30px #00d2ff; }
        #statusText { margin-top: 20px; font-weight: bold; color: #82baf7; text-transform: uppercase; letter-spacing: 1px; }
        #log { 
            margin-top: 20px; font-size: 10px; width: 90%; height: 80px; 
            overflow-y: auto; background: rgba(0,0,0,0.4); padding: 10px; 
            border-radius: 5px; font-family: monospace; color: #aaa;
        }
    </style>
</head>
<body>
    <div class="status-indicator" id="statusIndicator"></div>
    <div id="statusText">System Initializing...</div>
    <div id="log"></div>

<script type="module">
    import { AudioAnalysis } from './audio_analysis.js';

    const BASE_URL = "https://tel-retreat-pure-education.trycloudflare.com"; 
    const SAMPLE_RATE = 16000;

    let audioCtx = null;
    let streamNode = null;
    let analyser = null;
    let leftoverByte = null;
    let isProcessing = false;

    function log(msg) {
        const el = document.getElementById("log");
        const div = document.createElement("div");
        div.textContent = `[${new Date().toLocaleTimeString()}] ${msg}`;
        el.appendChild(div);
        el.scrollTop = el.scrollHeight;
    }

    /**
     * Initializes the AudioContext. 
     * We use async/await here to ensure the Worklet is fully loaded before continuing.
     */
    async function initAudio() {
        if (audioCtx) return;
        
        try {
            audioCtx = new (window.AudioContext || window.webkitAudioContext)({ 
                sampleRate: SAMPLE_RATE,
                latencyHint: 'playback' 
            });

            // Ensure module is loaded before creating the node
            await audioCtx.audioWorklet.addModule('stream_processor.js');
            
            streamNode = new AudioWorkletNode(audioCtx, 'stream_processor');
            analyser = audioCtx.createAnalyser();
            analyser.fftSize = 2048;                          // changed from 512
            
            streamNode.connect(analyser);
            analyser.connect(audioCtx.destination);
            
            // Resume context (crucial for modern browsers)
            await audioCtx.resume();
            
            log("âœ… Audio Worklet Thread Ready");
            document.getElementById("statusText").textContent = "Streaming Live";
            
            // Connect to the data source
            connectSSE();
            startVisualizerLoop();
        } catch (e) {
            log("âŒ Audio Engine Error: " + e.message);
            console.error(e);
        }
    }

    /**
     * Async handler for incoming audio packets.
     * This prevents the SSE stream from "piling up" and breaking the voice.
     */
    async function handleAudioData(base64) {
        // If we haven't set up the stream or are overloaded, return early
        if (!streamNode) return;

        // Using a microtask to ensure we don't block the main SSE event loop
        // await new Promise(resolve => setTimeout(resolve, 0));              //changed

        try {
            const binary = atob(base64);
            let bytes = new Uint8Array(binary.length);
            for (let i = 0; i < binary.length; i++) bytes[i] = binary.charCodeAt(i);

            // PCM Byte Alignment (Stitching)
            if (leftoverByte !== null) {
                let stitched = new Uint8Array(bytes.length + 1);
                stitched[0] = leftoverByte;
                stitched.set(bytes, 1);
                bytes = stitched;
                leftoverByte = null;
            }
            if (bytes.length % 2 !== 0) {
                leftoverByte = bytes[bytes.length - 1];
                bytes = bytes.slice(0, bytes.length - 1);
            }

            const float32 = new Float32Array(bytes.length / 2);
            const view = new DataView(bytes.buffer);
            for (let i = 0; i < float32.length; i++) {
                // Divide by 32768 to normalize Int16 to Float32 [-1.0, 1.0]
                float32[i] = view.getInt16(i * 2, true) / 32768.0;
            }

            // Post to the high-priority AudioWorklet thread
            streamNode.port.postMessage({ event: 'write', buffer: float32 });

        } catch (err) {
            console.error("PCM Processing Error:", err);
        }
    }

    /**
     * SSE Connection.
     */
    function connectSSE() {
        const ev = new EventSource(`${BASE_URL}/listen_audio`);
        
        // Use an async wrapper for the event listener
        ev.addEventListener("audio", async (e) => {
            await handleAudioData(e.data);
        });
        
        ev.onopen = () => log("ðŸ”Œ SSE Connection Established");
        ev.onerror = () => {
            log("ðŸ“¡ SSE Connection Lost. Reconnecting...");
            ev.close();
            setTimeout(connectSSE, 2000);
        };
    }

    /**
     * Visualizer Loop.
     */
    function startVisualizerLoop() {
        const indicator = document.getElementById("statusIndicator");
        
        function update() {
            requestAnimationFrame(update);
            if (!analyser) return;

            const data = AudioAnalysis.getFrequencies(analyser, SAMPLE_RATE, null, 'voice');
            const vol = data.values.reduce((a, b) => a + b, 0) / data.values.length;
            
            if (vol > 0.04) {
                indicator.classList.add("speaking");
            } else {
                indicator.classList.remove("speaking");
            }
        }
        update();
    }
    
    /**
     * Delayed Start Logic.
     */
    function startDelayedAudio(delayMs) {
        log(`â³ System standby: ${delayMs}ms...`);
        
        setTimeout(async () => {
            log("ðŸš€ Initializing Audio Engine...");
            await initAudio();
        }, delayMs);
    }

    // Recall Bots will trigger this automatically on load
    window.onload = () => {
        // 8 seconds delay as requested to let the bot environment stabilize
        startDelayedAudio(8000); 
    };

    // Manual fallback for local testing
    // window.onclick = () => initAudio();
</script>
</body>
</html>