<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <title>Recall.ai - Smooth PCM Stream</title>
    <style>
        body { display: flex; flex-direction: column; justify-content: center; align-items: center; height: 100vh; margin: 0; background: #0c0cf8; font-family: sans-serif; color: white; }
        .status-indicator { width: 120px; height: 120px; border-radius: 50%; background-color: #82baf7; display: flex; justify-content: center; align-items: center; margin-bottom: 20px; border: 4px solid rgba(255,255,255,0.2); transition: transform 0.1s; }
        .speaking { background-color: #00d2ff; box-shadow: 0 0 50px #00d2ff; transform: scale(1.1); }
        #log { font-size: 11px; width: 80%; height: 100px; overflow-y: auto; background: rgba(0,0,0,0.2); padding: 10px; border-radius: 6px; font-family: monospace; }
    </style>
</head>
<body>
    <div class="status-indicator" id="statusIndicator">‚óè</div>
    <div id="statusText">Click to Connect</div>
    <div id="log"></div>

<script type="module">
    import { AudioAnalysis } from './audio_analysis.js';

    const BASE_URL = "https://tel-retreat-pure-education.trycloudflare.com"; 
    const SAMPLE_RATE = 16000;
    const JITTER_BUFFER_MS = 500; // Increased to 500ms for extra safety

    let audioCtx = null;
    let streamNode = null;
    let analyser = null;
    
    // --- STITCHING STATE ---
    let leftoverByte = null; 
    let prefillBuffer = [];
    let isPlaying = false;

    function log(msg) {
        const el = document.getElementById("log");
        el.innerHTML += `<div>[${new Date().toLocaleTimeString()}] ${msg}</div>`;
        el.scrollTop = el.scrollHeight;
    }

    async function initAudio() {
        if (audioCtx) return;
        audioCtx = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: SAMPLE_RATE });
        await audioCtx.audioWorklet.addModule('stream_processor.js');
        streamNode = new AudioWorkletNode(audioCtx, 'stream_processor');
        analyser = audioCtx.createAnalyser();
        streamNode.connect(analyser);
        analyser.connect(audioCtx.destination);
        await audioCtx.resume();
        log("‚úÖ System Started");
        connectSSE();
    }

    function handleIncomingAudio(base64) {
        if (!streamNode) return;

        // 1. Convert Base64 to Raw Bytes
        const binaryString = atob(base64);
        let rawBytes = new Uint8Array(binaryString.length);
        for (let i = 0; i < binaryString.length; i++) rawBytes[i] = binaryString.charCodeAt(i);

        // 2. BYTE STITCHING: Handle "Split" PCM Samples
        // If we had a leftover byte from the last packet, put it at the start
        if (leftoverByte !== null) {
            let newBytes = new Uint8Array(rawBytes.length + 1);
            newBytes[0] = leftoverByte;
            newBytes.set(rawBytes, 1);
            rawBytes = newBytes;
            leftoverByte = null;
        }

        // If this packet has an odd number of bytes, save the last one for later
        if (rawBytes.length % 2 !== 0) {
            leftoverByte = rawBytes[rawBytes.length - 1];
            rawBytes = rawBytes.slice(0, rawBytes.length - 1);
        }

        // 3. Convert to Float32
        const dataView = new DataView(rawBytes.buffer);
        const float32 = new Float32Array(rawBytes.length / 2);
        for (let i = 0; i < float32.length; i++) {
            float32[i] = dataView.getInt16(i * 2, true) / 32768.0;
        }

        // 4. JITTER BUFFERING
        if (!isPlaying) {
            prefillBuffer.push(...float32);
            if (prefillBuffer.length >= (SAMPLE_RATE * (JITTER_BUFFER_MS / 1000))) {
                streamNode.port.postMessage({ event: 'write', buffer: new Float32Array(prefillBuffer) });
                prefillBuffer = [];
                isPlaying = true;
                log("üöÄ Buffering complete, audio playing");
            }
        } else {
            streamNode.port.postMessage({ event: 'write', buffer: float32 });
        }
    }

    function connectSSE() {
        const eventSource = new EventSource(`${BASE_URL}/listen_audio`);
        eventSource.addEventListener("audio", (e) => handleIncomingAudio(e.data));
        
        // Setup visualizer
        function draw() {
            requestAnimationFrame(draw);
            if (!analyser) return;
            const data = AudioAnalysis.getFrequencies(analyser, SAMPLE_RATE, null, 'voice');
            const vol = data.values.reduce((a, b) => a + b, 0) / data.values.length;
            document.getElementById("statusIndicator").className = vol > 0.05 ? "status-indicator speaking" : "status-indicator";
        }
        draw();
    }

    window.onload = () => initAudio();
</script>
</body>
</html>